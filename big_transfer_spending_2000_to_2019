import requests
import csv
from bs4 import BeautifulSoup


headers = {'User-Agent': 
           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36'}
PlayersList = []
ValuesList = []
YearList = []
BuyerList=[]

for i in range(2000,2019):
    for j in range(1,3):
        page = "https://www.transfermarkt.co.uk/transfers/transferrekorde/statistik/top/plus/0/galerie/0/page/"+str(j)+"/?saison_id="+str(i)
        pageTree = requests.get(page, headers=headers)
        pageSoup = BeautifulSoup(pageTree.content, 'html.parser')

        Players = pageSoup.find_all("a", {"class": "spielprofil_tooltip"})
        Values = pageSoup.find_all("td", {"class": "rechts hauptlink"})
        Buyers=pageSoup.find_all("a",{"class":"vereinprofil_tooltip"})
        Year=i

        for i in range(0,25):
            try:
                PlayersList.append(Players[i].text)
                ValuesList.append(Values[i].text)
                BuyerList.append(Buyers[2*i+1].text)
                YearList.append(Year)
            except IndexError:
                continue

with open('transfer_data.csv', 'w', encoding="UTF-16",newline="") as f:
    writer = csv.writer(f)
    for row in zip(PlayersList,ValuesList,YearList,BuyerList):
        writer.writerow(row)
